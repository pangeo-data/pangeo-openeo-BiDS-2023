{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to exploit data on Pangeo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Pangeo Workshop - Snow and Cloud Cover\n",
    "converted from https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/3.1_data_processing/exercises/_alternatives/31_data_processing_stac.ipynb\n",
    "\n",
    "author: Michele Clous @mclous\n",
    "conversion by: Pangeo volunteers (Pier Lorenzo Marasco @pl-marasco, Alejandro Coca-Castro @, Justus Magin @ , Tina Odaka @tinaodaka, Anne fouilloux @annefou)\n",
    "\n",
    "#### Introduction\n",
    "In this exercise, we will build a complete the same EO workflow as OpenEO using cloud provided data (STAC Catalogue), processing it locally; from data access to obtaining the result.\n",
    "\n",
    "We are going to follow these steps in our analysis:\n",
    "\n",
    "- Load satellite collections\n",
    "- Specify the spatial, temporal extents and the features we are interested in\n",
    "- Process the satellite data to retrieve snow cover information\n",
    "- aggregate information in data cubes\n",
    "- Visualize and analyse the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###\n",
    "Important Infos \n",
    "\n",
    "More information on Pangeo can be found here: https://pangeo.io/\n",
    "More information on the STAC specification can be found here: https://stacspec.org/\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Manipulation and Analysis Libraries\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "\n",
    "# Geospatial Data Handling Libraries\n",
    "import geopandas as gpd \n",
    "from shapely.geometry import mapping  \n",
    "import pyproj\n",
    "\n",
    "# Multidimensional and Satellite Data Libraries\n",
    "import xarray as xr \n",
    "import rioxarray as rio\n",
    "import stackstac\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "\n",
    "# Data parallelization and distributed computing libraries\n",
    "import dask\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "\n",
    "# STAC Catalogue Libraries\n",
    "import pystac_client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aoi = gpd.read_file('data/catchment_outline.geojson', crs=\"EPGS:4326\")\n",
    "aoi_geojson = mapping(aoi.iloc[0].geometry)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "URL = \"https://earth-search.aws.element84.com/v1\"\n",
    "catalog = pystac_client.Client.open(URL)\n",
    "items = catalog.search(\n",
    "    intersects=aoi_geojson,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=\"2019-02-01/2019-06-10\"\n",
    ").item_collection()\n",
    "len(items)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get bands information\n",
    "# selected_item = items[1]\n",
    "# for key, asset in selected_item.assets.items():\n",
    "#     print(f\"{key}: {asset.title}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds = stackstac.stack(items)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "green = ds.sel(band='green')\n",
    "swir = ds.sel(band='swir16')\n",
    "scl = ds.sel(band='scl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndsi = (green - swir) / (green + swir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ndsi = ndsi.chunk(chunks={'time':1, 'x': 2048, 'y': 2048})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow = xr.where((ndsi > 0.42) & ~np.isnan(ndsi), 1, ndsi)\n",
    "snowmap = xr.where((snow <= 0.42) & ~np.isnan(snow), 0, snow)\n",
    "# mask = (scl != 8) & (scl != 9) & (scl != 3) \n",
    "mask = np.logical_not(scl.isin([8, 9, 3]))  # more elegant but not sure about it from a teaching perspective\n",
    "snow_cloud = xr.where(mask, snowmap, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aoi_utm32 = aoi.to_crs(epsg=32632)\n",
    "geom_utm32 = aoi_utm32.iloc[0]['geometry']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow_cloud.rio.write_crs(\"EPSG:32632\", inplace=True)\n",
    "snow_cloud.rio.set_nodata(np.nan, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snowmap_clipped = snow_cloud.rio.clip([geom_utm32])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from dask.diagnostics import ProgressBar\n",
    "# with ProgressBar():\n",
    "#     clipped_date = snowmap_clipped.compute()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clipped_date = snowmap_clipped.compute()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "progress(clipped_date)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clipped_date = snowmap_clipped.groupby(snowmap_clipped.time.dt.floor('D')).max(skipna=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clipped_date = clipped_date.rename({'floor': 'date'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clipped_date"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clipped_date.hvplot.image(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    groupby='date',\n",
    "    crs=pyproj.CRS.from_epsg(32632),\n",
    "    cmap='Pastel2',\n",
    "    clim=(-1, 2),\n",
    "    frame_width=500,\n",
    "    frame_height=500,\n",
    "    title='Snowmap',\n",
    "    geo=True, tiles='OSM')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloud = xr.where(clipped_date == 2, 1, np.nan).count(dim=['x', 'y'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aot_total = clipped_date.count(dim=['x', 'y'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloud_fraction = cloud / aot_total * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloud_fraction.hvplot.line(title='Cloud cover %', ylabel=\"&\") * hv.HLine(25).opts(\n",
    "    color='red',\n",
    "    line_dash='dashed',\n",
    "    line_width=2.0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow = xr.where(clipped_date == 1, 1, np.nan).count(dim=['x', 'y'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow_fraction = snow / aot_total * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow_fraction.hvplot.line(title='Snow cover area (%)', ylabel=\"%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "masked_cloud_fraction = cloud_fraction < 30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow_selected = snow_fraction.sel(date=masked_cloud_fraction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow_selected.name = 'SCA'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snow_selected.hvplot.line(title=\"Snow fraction\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discharge_ds = pd.read_csv('data/ADO_DSC_ITH1_0025.csv', sep=',', index_col='Time', parse_dates=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discharge_ds.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(\"2019/02/01\")\n",
    "end_date = pd.to_datetime(\"2019/06/30\")\n",
    "# filter discharge data to start and end dates\n",
    "discharge_ds = discharge_ds.loc[start_date:end_date]\n",
    "\n",
    "discharge_ds.discharge_m3_s.hvplot(title='Discharge volume', ylabel='Discharge (m$^3$/s)') * snow_selected.hvplot(ylabel='Snow cover area (%)')  "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
